{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OwkNI7cLlSDriq_0MKOM5LOA9yPFJEmZ",
      "authorship_tag": "ABX9TyNE87sGcC0fEaG4HLy9puwu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PVl6AJvqd_J"
      },
      "outputs": [],
      "source": [
        "!pip install torch transformers coremltools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer, BertConfig\n",
        "import torch\n",
        "\n",
        "enc = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "\n",
        "# Create dummy input\n",
        "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
        "tokenized_text = enc.tokenize(text)\n",
        "\n",
        "masked_index = 8\n",
        "tokenized_text[masked_index] = \"[MASK]\"\n",
        "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
        "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "dummy_input = [tokens_tensor, segments_tensors]"
      ],
      "metadata": {
        "id": "IqQ-SWG7xWcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trace the model\n",
        "model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\", torchscript=True)\n",
        "model.eval()\n",
        "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])"
      ],
      "metadata": {
        "id": "TurOEEKp0pY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "\n",
        "# Convert into Core ML-compatible format\n",
        "coreml_model = ct.convert(\n",
        "  traced_model,\n",
        "    inputs=[\n",
        "      ct.TensorType(shape=dummy_input[0].shape, name=\"input_ids\"),  # Renamed and matched to the first input\n",
        "      ct.TensorType(shape=dummy_input[1].shape, name=\"attention_mask\")  # Added the second input\n",
        "  ],\n",
        "  outputs=[\n",
        "      ct.TensorType(name=\"last_hidden_state\"),  # Output for the last hidden state\n",
        "      ct.TensorType(name=\"pooler_output\")  # Output for the pooler output\n",
        "  ])"
      ],
      "metadata": {
        "id": "DGG8f420xgX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Core ML model\n",
        "coreml_model.save(\"bert-base-uncased.mlpackage\")"
      ],
      "metadata": {
        "id": "x8GLmzBkypUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bert-base-uncased.mlpackage.zip /content/bert-base-uncased.mlpackage"
      ],
      "metadata": {
        "id": "dlJ2MUKEzWCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"bert-base-uncased.mlpackage.zip\")"
      ],
      "metadata": {
        "id": "UGR-1bmnzgww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}